{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaRED Library Processing DEMO\n",
    "\n",
    "In this tutorial, we will explore the data processing functions available in the SpaRED library, focusing on four key areas:\n",
    "\n",
    "* Gene Features\n",
    "* Filtering\n",
    "* Layer Operations\n",
    "* Denoising\n",
    "\n",
    "These processing functions are essential for preparing and refining spatial transcriptomics data, ensuring that it is ready for accurate and efficient analysis. This demonstration will showcase the preprocessing steps used in our paper, providing a detailed look at how to clean your data, extract meaningful features, and perform various operations on data layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/SSD4/dvegaa/SpaRED\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as im\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "currentdir = os.getcwd()\n",
    "parentdir = str(Path(currentdir).parent)\n",
    "sys.path.insert(0, parentdir)\n",
    "print(parentdir)\n",
    "\n",
    "import spared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets\n",
    "\n",
    "The `datasets` file has a function to get any desired dataset and return the adata as well as the parameter dictionary. This function returns a filtered and processed adata. This function has a parameter called *visualize* that allows for all visualizations if set to True. The fuction also saves the raw_adata (not processed) in case it is required. \n",
    "\n",
    "We will begin by loading a dataset and setting the *visualize* parameter as False since no images are required for the functions analized in this DEMO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.datasets import get_dataset\n",
    "import anndata as ad\n",
    "\n",
    "#get dataset\n",
    "data = get_dataset(\"vicari_mouse_brain\", visualize=False)\n",
    "\n",
    "#adata\n",
    "adata = data.adata\n",
    "\n",
    "#parameters dictionary\n",
    "param_dict = data.param_dict\n",
    "\n",
    "#loading raw adata \n",
    "dataset_path = os.getcwd()\n",
    "files_path = os.path.join(dataset_path, \"processed_data/vicari_data/vicari_mouse_brain/\")\n",
    "files = os.listdir(files_path)\n",
    "adata_path = os.path.join(files_path, files[0], \"adata_raw.h5ad\")\n",
    "raw_adata = ad.read_h5ad(adata_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene features functions\n",
    "\n",
    "In this section, we will explore the gene features functions available in the SpaRED library. These functions provide tools to compute the relative and global expression fractions for all genes, as well as the Moran's I for genes in an AnnData object. These calculations provide insights into gene expression patterns and their spatial distribution, and are also used in the preprocessing steps.\n",
    "\n",
    "### Function: `get_exp_frac`\n",
    "\n",
    "The `get_exp_frac` function calculates the expression fraction of each gene within individual slides. This function is essential for understanding the local expression patterns of genes across different spatial regions.\n",
    "\n",
    "##### <u>Parameters:</u>\n",
    "\n",
    "* **adata (ad.AnnData):** adata collection where non-expressed genes have a value of `0` in the `adata.X` matrix\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "An updated AnnData object with the expression fraction information added into the `adata.var['exp_frac']` column. The expression fraction of a gene in a slide is defined as the proportion of spots where that gene is expressed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.gene_features import get_exp_frac\n",
    "\n",
    "adata_exp = get_exp_frac(raw_adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `get_glob_exp_frac`\n",
    "\n",
    "The `get_glob_exp_frac` function calculates the global expression fraction of each gene across the entire dataset. This measure provides a broader view of gene expression patterns, allowing for comparisons across different slides.\n",
    "\n",
    "##### <u>Parameters:</u>\n",
    "\n",
    "* **adata (ad.AnnData):** adata collection where non-expressed genes have a value of `0` in the `adata.X` matrix\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "An updated AnnData object with the global expression fraction information added into the `adata.var['glob_exp_frac']` column. The global expression fraction of a gene in a dataset is defined as the proportion of spots where that gene is expressed across the entire dataset, as opposed to individual slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.gene_features import get_glob_exp_frac\n",
    "\n",
    "adata_exp = get_glob_exp_frac(raw_adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `compute_moran`\n",
    "\n",
    "The `compute_moran` function calculates Moran's I for each gene, providing a measure of spatial autocorrelation. Moran's I indicates whether gene expression levels are more similar (positive autocorrelation) or more dissimilar (negative autocorrelation) across spatial locations than would be expected by chance. Genes with high Moran's I values exhibit strong spatial patterns in their expression levels.\n",
    "\n",
    "##### <u>Parameters:</u>\n",
    "\n",
    "* **adata (ad.AnnData):** An AnnData object to update. Must have expression values in `adata.layers[from_layer]`.\n",
    "* **from_layer (str):** Key in `adata.layers` with the values used to compute Moran's I.\n",
    "* **hex_geometry (bool):** Whether the geometry is hexagonal or not.\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "An updated AnnData object with the average Moran's I for each gene in the `adata.var[f'{from_layer}_moran']` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.gene_features import compute_moran\n",
    "\n",
    "adata_moran = compute_moran(adata=adata, from_layer=\"c_d_log1p\", hex_geometry=param_dict[\"hex_geometry\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering functions\n",
    "\n",
    "In this section, we will explore the filtering functions available in the SpaRED library. These functions are designed to refine your spatial transcriptomics data by filtering it based on specific criteria. Specifically, we will demonstrate how to filter AnnData objects (adata) by Moran's I genes, using the parameters defined in `param_dict` and based on specific slides.\n",
    "\n",
    "### Function: `filter_by_moran`\n",
    "\n",
    "The `filter_by_moran` function refines the dataset by selecting genes with the highest Moran's I values, which indicates strong spatial autocorrelation. This ensures that the analysis focuses on genes with meaningful spatial patterns, which is crucial for spatial transcriptomics studies.\n",
    "\n",
    "##### <u>Parameters:</u>\n",
    "\n",
    "* **adata (ad.AnnData):** An AnnData object to update. The AnnData must contain an `adata.var[f'{from_layer}_moran']` column.\n",
    "* **n_keep (int):** The number of genes to keep in the filtering process.\n",
    "* **from_layer (str):** The layer for which the Moran's I was previously computed.\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "An updated AnnData object with the filtered genes.\n",
    "\n",
    "### Filtering by Moran's I values\n",
    "**Moran's I** is a measure of spatial autocorrelation, indicating whether gene expression levels are more similar (positive autocorrelation) or more dissimilar (negative autocorrelation) across spatial locations than would be expected by chance. This indicates which genes present spatial patterns with biological meaning instead of random patterns.\n",
    "\n",
    "The `filter_by_moran` function ranks all the genes present in the data by their Moran I values, obtained from `compute_moran`. Then, it selects the top genes with the highest values (e.g., the top 256 genes), ensuring that the analysis focuses only on those with meaningful spatial variation and not random spatial patterns. This is crucial for spatial transcriptomics studies to identify and analyze biologically significant spatial patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.filtering import filter_by_moran\n",
    "\n",
    "adata_moran = filter_by_moran(adata, n_keep=param_dict['top_moran_genes'], from_layer='d_log1p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `filter_dataset` \n",
    "\n",
    "The `filter_dataset` function refines the dataset by applying a series of filters to ensure the data is meaningful and robust for analysis. This function filters both spots and genes based on user-defined criteria provided in the param_dict.\n",
    "\n",
    "##### <u>Parameters:</u>\n",
    "\n",
    "* **adata(ad.AnnData):** An unfiltered AnnData collection.\n",
    "* **param_dict (dict):** A dictionary containing filtering and processing parameters. In the `param_dict`, the following keys must be present:\n",
    "\n",
    "    * `cell_min_counts` (*int*):      Minimum total counts for a spot to be valid.\n",
    "    * `cell_max_counts` (*int*):      Maximum total counts for a spot to be valid.\n",
    "    * `gene_min_counts` (*int*):      Minimum total counts for a gene to be valid.\n",
    "    * `gene_max_counts` (*int*):      Maximum total counts for a gene to be valid.\n",
    "    * `min_exp_frac` (*float*):       Minimum fraction of spots in any slide that must express a gene for it to be valid.\n",
    "    * `min_glob_exp_frac` (*float*):  Minimum fraction of spots in the whole collection that must express a gene for it to be valid.\n",
    "    * `wildcard_genes` (*str*):       Path to a `.txt` file with the genes to keep or `None` to filter genes based on the other keys.\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "A filtered AnnData collection.\n",
    "\n",
    "### Explanation\n",
    "\n",
    "The `filter_dataset` function applies several filters to ensure that the data is meaningful and robust:\n",
    "\n",
    "1. **Filter Spots by Total Counts:**\n",
    "\n",
    "    Spots with total counts outside the range [`param_dict['cell_min_counts']`, `param_dict['cell_max_counts']`] are removed. This ensures that all spots have a meaningful number of expressed genes, providing sufficient information for accurate predictions.\n",
    "\n",
    "2. **Filter Genes by Total Counts:**\n",
    "\n",
    "    Genes with total counts outside the range [`param_dict['gene_min_counts']`, `param_dict['gene_max_counts']`] are removed. This ensures that all genes have meaningful expression values, providing sufficient information for accurate predictions.\n",
    "\n",
    "3. **Filter Genes by Expression Fraction:**\n",
    "\n",
    "    If `param_dict['wildcard_genes']` is None, genes are filtered based on their expression fraction. Genes that are not expressed in at least `param_dict['min_exp_frac']` of spots in each slide and `param_dict['min_glob_exp_frac']` of spots in the whole collection are removed. This discards genes with low sparsity, leaving only those with significant expression occurrence.\n",
    "\n",
    "4. **Filter Genes by Wildcard Genes:**\n",
    "\n",
    "    If `param_dict['wildcard_genes']` is specified, only the genes listed in the file are kept.\n",
    "\n",
    "5. **Remove Genes with Zero Counts:**\n",
    "\n",
    "    Finally, genes with zero counts are removed to ensure the dataset is free from non-expressed genes.\n",
    "\n",
    "These filtering steps ensure that the model is provided with sufficient and meaningful data to learn expression patterns for each predicted or imputed gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.filtering import filter_dataset\n",
    "\n",
    "adata_filter = filter_dataset(adata, param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `get_slide_from_collection`\n",
    "\n",
    "The `get_slide_from_collection` function extracts a specific slide from a collection of concatenated slides in an AnnData object.\n",
    "\n",
    "##### <u>Parameters:</u>\n",
    "\n",
    "* **collection (ad.Anndata):** An AnnData object with all the slides concatenated.\n",
    "* **slide (str):** The name of the slide to extract from the collection.\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "A filtered AnnData object containing only the specified slide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.filtering import get_slide_from_collection\n",
    "\n",
    "slide_id = adata.obs.slide_id.unique()[0]\n",
    "slide_adata = get_slide_from_collection(collection = adata,  slide=slide_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `get_slides_adata` \n",
    "\n",
    "The `get_slides_adata` function extracts multiple slides from a collection of concatenated slides in an AnnData object, based on a list of slide names.\n",
    "\n",
    "##### <u>Parameters:</u>\n",
    "\n",
    "* **collection (ad.Anndata):** An AnnData object with several slides concatenated.\n",
    "* **slide_list (str):** A string containing a list of slide names separated by commas.\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "A list of AnnData objects, one for each slide included in the `slide_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.filtering import get_slides_adata\n",
    "\n",
    "all_slides = \",\".join(adata.obs.slide_id.unique().to_list())\n",
    "slides_list = get_slides_adata(collection=adata, slide_list=all_slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Operation functions\n",
    "\n",
    "In this section, we will explore the layer operation functions available in the SpaRED library. These functions provide essential tools for processing and normalizing transcriptomic data, ensuring accurate and meaningful comparisons across different samples or regions.\n",
    "\n",
    "### Function: `tpm_normalization` \n",
    "\n",
    "The `tpm_normalization` function applies TPM (Transcripts per Million) normalization to an AnnData object. This process adjusts the raw counts by gene length and library size, making the data comparable across different samples or regions.\n",
    "\n",
    "##### <u>Parameters:</u>\n",
    "\n",
    "* **adata (ad.AnnData):** The AnnData object to normalize. The counts are taken from `adata.layers[from_layer]`.\n",
    "* **organism (str):** Organism of the dataset. Must be 'mouse' or 'human'.\n",
    "* **from_layer (str):** The layer to take the counts from. The data in this layer should be in raw counts.\n",
    "* **to_layer (str):** The layer to store the results of the normalization.\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "An updated AnnData object with TPM values in `adata.layers[to_layer]`.\n",
    "\n",
    "### TPM Normalization\n",
    "\n",
    "The purpose behind TPM normalization is to make gene expression levels comparable between different samples or regions. The general framework for TPM normalization involves the following steps:\n",
    "\n",
    "1. **Count Reads per Gene:** For each gene in a sample, count the number of reads mapped to it. This gives the raw read counts.\n",
    "\n",
    "2. **Normalize for Gene Length:** Divide the raw read count for each gene by the length of the gene (in kilobases). This step adjusts for the fact that longer genes are more likely to have more reads simply because they are longer. The result is the RPK (Reads Per Kilobase).\n",
    "\n",
    "3. **Calculate the Scaling Factor:** Sum the RPK values for all genes in a sample to get a scaling factor. This represents the total number of reads per kilobase in the sample.\n",
    "\n",
    "4. **Normalize for Library Size:** Divide each gene's RPK by the scaling factor and then multiply by $10^6$ to get TPM (Transcripts Per Million). This step adjusts for the total sequencing depth (library size), making expression levels comparable across samples.\n",
    "\n",
    "TPM normalization accounts for both gene length and library size, making it possible to compare gene expression levels across different samples or regions accurately. It standardizes the data, ensuring that observed differences reflect biological variation rather than technical biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.layer_operations import tpm_normalization\n",
    "\n",
    "adata.layers['counts'] = adata.X.toarray()\n",
    "adata = tpm_normalization(adata=adata, organism=param_dict[\"organism\"], from_layer=\"counts\", to_layer=\"tpm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `log1p_transformation`\n",
    "\n",
    "The `log1p_transformation` function applies a log base 2 transformation to the data, stabilizing variance and improving the normality of the data. This transformation is particularly useful for gene expression data, which often follows a skewed distribution.\n",
    "\n",
    "##### <u>Parameters:</u>\n",
    "\n",
    "* **adata (ad.AnnData):** The AnnData object to transform.\n",
    "* **from_layer (str):** The layer to take the data from.\n",
    "* **to_layer (str):** The layer to store the results of the transformation.\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "An updated AnnData object with transformed data in `adata.layers[to_layer]`.\n",
    "\n",
    "### Log1p Transformation\n",
    "\n",
    "The purpose behind the log1p transformation is to stabilize the variance and improve the normality of the data, making the gene expression data more suitable for downstream analyses. The `log1p_transformation` function applies a log base 2 transformation to the TPM values and adds 1 to avoid taking the logarithm of zero.\n",
    "\n",
    "Gene expression data often follows a skewed distribution with a few genes having very high expression levels and many genes having low expression levels. By applying the log transformation, the data distribution becomes more symmetrical and closer to a normal distribution.\n",
    "\n",
    "The log transformation achieves this by compressing the range of expression values. High expression values are compressed more than low expression values, reducing the effect of outliers, while low expression values are expanded slightly, helping to distinguish between low but non-zero expression levels. This transformation also stabilizes the variance across the data. Variance stabilization means that the variability of the data becomes more consistent across different expression levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.layer_operations import log1p_transformation\n",
    "\n",
    "adata = log1p_transformation(adata, from_layer='tpm', to_layer='log1p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `combat_transformation`\n",
    "\n",
    "The `combat_transformation` function applies batch correction to the data using the ComBat algorithm, addressing technical variations and batch effects.\n",
    "\n",
    "##### <u>Parameters:</u>\n",
    "\n",
    "* **adata (ad.AnnData):** The AnnData object to transform. Must have logarithmically transformed data in `adata.layers[from_layer]`.\n",
    "* **batch_key (str):** The column in `adata.obs` that defines the batches.\n",
    "* **from_layer (str):** The layer to take the data from.\n",
    "* **to_layer (str):** The layer to store the results of the transformation.\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "An updated AnnData object with batch-corrected data in `adata.layers[to_layer]`.\n",
    "\n",
    "### ComBat Transformation\n",
    "\n",
    "The purpose behind the ComBat transformation is to correct for batch effects and other technical variations between samples. Batch effects are unwanted variations that arise from differences in sample processing, such as differences in sequencing runs, sample preparation, or other technical factors. The ComBat algorithm adjusts for these variations by modeling the expression data as a combination of biological signal and batch effect. It estimates the batch effect parameters and removes them from the data, producing a corrected dataset.\n",
    "\n",
    "Batch effects can introduce systematic biases that obscure true biological differences between samples. ComBat correction ensures that the observed variations in gene expression reflect genuine biological differences rather than technical artifacts, improving the reliability and accuracy of downstream analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.layer_operations import combat_transformation\n",
    "\n",
    "adata = combat_transformation(adata, batch_key=param_dict['combat_key'], from_layer='log1p', to_layer='c_log1p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `get_deltas`\n",
    "\n",
    "The `get_deltas` function calculates the deviations (deltas) from the mean expression of each gene and stores these values in a specified layer of the AnnData object.\n",
    "\n",
    "##### <u>Parameters:</u>\n",
    "\n",
    "* **adata (ad.AnnData):** The AnnData object to update. Must have expression values in `adata.layers[from_layer]`. Must also have the `adata.obs['split']` column with 'train' values.\n",
    "* **from_layer (str):** The layer to take the data from.\n",
    "* **to_layer (str):** The layer to store the results of the transformation.\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "An updated AnnData object with the deltas in `adata.layers[to_layer]` and mean expression information in `adata.var[f'{from_layer}_avg_exp']`.\n",
    "\n",
    "### Deltas\n",
    "\n",
    "The delta value represents the difference between the actual gene expression value and the mean expression value in the training dataset. Research, including studies by Mejia, G et al., has shown that predicting expression variations (deltas) rather than absolute expression values leads to better performance in gene expression prediction tasks, as evidenced by lower Mean Squared Error (MSE). This approach reduces prediction error and enhances the accuracy and reliability of downstream analyses, thereby improving the overall performance in understanding and interpreting gene expression patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.layer_operations import get_deltas\n",
    "\n",
    "adata = get_deltas(adata, from_layer='log1p', to_layer='deltas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `add_noisy_layer` \n",
    "\n",
    "The `add_noisy_layer` function adds an artificial noisy layer to the AnnData object for experimentation or ablation purposes. This function corrupts the specified prediction layer by introducing noise, either by setting missing values to zero (for log-transformed data) or to the negative mean expression (for delta data).\n",
    "\n",
    "##### <u>Parameters:</u>\n",
    "\n",
    "* **adata (ad.AnnData):** The AnnData object to update. Must have the prediction layer, the gene means if it's a delta layer, and the mask layer.\n",
    "* **prediction_layer (str):** The layer that will be corrupted to create the noisy layer.\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "An updated AnnData object with the noisy layer added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.layer_operations import add_noisy_layer\n",
    "\n",
    "adata.layers['mask'] = adata.layers['tpm'] != 0\n",
    "adata = add_noisy_layer(adata=adata, prediction_layer=\"c_log1p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `process_dataset` \n",
    "\n",
    "The `process_dataset` function performs a complete processing pipeline on a filtered AnnData object, applying various transformations and normalizations. This function integrates several preprocessing steps, ensuring the data is ready for accurate and robust analysis.\n",
    "\n",
    "##### <u>Parameters:</u>\n",
    "\n",
    "* **adata (ad.AnnData):** AnnData object to process. The AnnData should be already filtered\n",
    "* **param_dict (dict):** Dictionary that contains filtering and processing parameters. Keys that must be present are:\n",
    "    * `top_moran_genes (int):` The number of genes to keep after filtering by Moran's I. If set to 0, then the number of genes is internally computed\n",
    "    * `combat_key (str):` The column in adata.obs that defines the batches for ComBat batch correction. If set to 'None', then no batch correction is performed.\n",
    "    * `hex_geometry (bool)` Whether the graph is hexagonal or not. If True, then the graph is hexagonal. If False, then the graph is a grid. Only true for visium datasets.\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "A processed AnnData object with all the layers and results added. A list of included layers in adata.layers is:\n",
    "\n",
    "* `counts`: Raw counts of the dataset.\n",
    "* `tpm`: TPM normalized data.\n",
    "* `log1p`: Log1p transformed data (base 2.0).\n",
    "* `d_log1p`: Denoised data with adaptive median filter.\n",
    "* `c_log1p`: Batch corrected data with ComBat (only if combat_key is not 'None').\n",
    "* `c_d_log1p`: Batch corrected and denoised data with adaptive median filter (only if combat_key is not 'None').\n",
    "* `deltas`: Deltas from the mean expression for log1p.\n",
    "* `d_deltas`: Deltas from the mean expression for d_log1p.\n",
    "* `c_deltas`: Deltas from the mean expression for c_log1p (only if combat_key is not 'None').\n",
    "* `c_d_deltas`: Deltas from the mean expression for c_d_log1p (only if combat_key is not 'None').\n",
    "* `mask`: Binary mask layer. True for valid observations, False for imputed missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.layer_operations import process_dataset\n",
    "\n",
    "raw_adata = ad.read_h5ad(os.path.join(dataset_path, f'adata_raw.h5ad'))\n",
    "processed_adata = process_dataset(adata=raw_adata, param_dict=param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising functions\n",
    "\n",
    "In this section, we will explore the denoising functions available in the SpaRED library. These functions are designed to address and fill missing data, often referred to as dropout values, using methods such as the median imputation strategy, highlighted in (Mejia et al., 2023), and the innovative SpaCKLE method, as detailed in our publication (Mejia et al., 2023).\n",
    "\n",
    "### Median imputation\n",
    "\n",
    "Median imputation strategies replaces zero values in the gene map  with the median of a growing circular region around the interest patch up to the 7th unique radial distance. If no value is obtained at the end of this process, the median of nonzero entries of the WSI is applied.\n",
    "\n",
    "### Function: `median_cleaner`\n",
    "\n",
    "The `median_cleaner` function processes the AnnData object using an adaptive median filter method for denoising and filling in missing \n",
    "\n",
    "##### <u>Parameters:</u>\n",
    "\n",
    "* **collection (ad.AnnData):** The AnnData collection to process.\n",
    "* **from_layer (str):** The layer to compute the adaptive median filter from. Where to clean the noise from.\n",
    "* **to_layer (str):** The layer to store the results of the adaptive median filter. Where to store the cleaned data.\n",
    "* **n_hops (int):** The maximum number of concentric rings in the neighbors graph to take into account to compute the median. Analogous to the maximum window size.\n",
    "* **hex_geometry (bool):** True if the graph has hexagonal spatial geometry (Visium technology). If False, then the graph is a grid.\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "An updated AnnData collection with the results of the adaptive median filter stored in the layer  `adata.layers[to_layer]`.\n",
    "\n",
    "To properly use `median_cleaner`, it is essential that the global expression fraction has been previously calculated and saved in the `AnnData` collection. Furthermore, the dataset should have undergone TPM normalization and log1p transformation to ensure accurate and effective noise removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.denoising import median_cleaner\n",
    "\n",
    "# Get global exp fraction\n",
    "adata = get_glob_exp_frac(raw_adata)\n",
    "# X to array\n",
    "adata.layers['counts'] = adata.X.toarray()\n",
    "# TPM normalization\n",
    "adata = tpm_normalization(param_dict[\"organism\"], adata, from_layer='counts', to_layer='tpm')\n",
    "# Transform the data with log1p (base 2.0)\n",
    "adata = log1p_transformation(adata, from_layer='tpm', to_layer='log1p')\n",
    "\n",
    "adata = median_cleaner(adata, from_layer='log1p', to_layer='d_log1p', n_hops=4, hex_geometry=param_dict[\"hex_geometry\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaCKLE imputation \n",
    "\n",
    "SpaCKLE imputations strategie leverages the power of Transformers to complete corrupted gene expression vectors. This method outperforms previous gene completion strategies and is able to succesfully complete dropout values even when the missing data fraction is up to 70%. \n",
    "\n",
    "### Function: `spackle_cleaner`\n",
    "\n",
    "The `spackle_cleaner` function processes the AnnData object using the SpaCKLE method for denoising and filling in missing data. \n",
    "\n",
    "##### <u>Parameters:</u>\n",
    "\n",
    "* **adata (ad.AnnData):** The AnnData object to process. Must have data splits in `adata.obs['split']` with values 'train', 'val', and (optional) 'test'.\n",
    "* **dataset (str):** The name of the dataset being processed.\n",
    "* **from_layer (str):** The layer to take the data from for processing.\n",
    "* **to_layer (str):** The layer to store the results of the SpaCKLE denoising process.\n",
    "* **device (str):** The device to run the model on (e.g., 'cpu' or 'cuda').\n",
    "* **lr (float):** The learning rate for training the model. Default is 1e-3.\n",
    "* **train (bool):** Indicates whether to train a new model or use an existing one. Default is True.\n",
    "* **get_performance_metrics (bool):** Indicates whether to compute performance metrics. Default is True.\n",
    "* **load_ckpt_path (str):** Path to the checkpoint file of a pre-trained model. If provided, training is skipped. Default is an empty string.\n",
    "* **optimizer (str):** The optimizer to use for training. Default is 'Adam'.\n",
    "* **max_steps (int):** The maximum number of training steps. Default is 1000.\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "An updated AnnData object with the denoised layer added and the path to the model's checkpoints used for completing the missing values.\n",
    "\n",
    "To properly use the `spackle_cleaner` function, several preprocessing steps must be completed to ensure the data is adequately prepared for the denoising process. These steps include computing the average Moran's I for each gene, filtering genes based on their Moran's I values, applying ComBat batch correction, and adding a binary mask layer. Additionally, for optimal performance, the function requires a GPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.denoising import spackle_cleaner\n",
    "import torch \n",
    "\n",
    "# Compute average moran for each gene in the layer d_log1p \n",
    "adata = compute_moran(adata, hex_geometry=param_dict[\"hex_geometry\"], from_layer='d_log1p')\n",
    "# Filter genes by Moran's I\n",
    "adata = filter_by_moran(adata, n_keep=param_dict['top_moran_genes'], from_layer='d_log1p')\n",
    "# Apply combat\n",
    "adata = combat_transformation(adata, batch_key=param_dict['combat_key'], from_layer='d_log1p', to_layer='c_d_log1p')\n",
    "# Add a binary mask layer \n",
    "adata.layers['mask'] = adata.layers['tpm'] != 0\n",
    "# Define a device\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "adata_1, _  = spackle_cleaner(adata=adata, dataset=data.dataset, from_layer=\"c_d_log1p\", to_layer=\"c_t_log1p\", device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `spackle_cleaner_experiment`\n",
    "\n",
    "The `spackle_cleaner_experiment` function is designed to replicate the results presented in the SpaCKLE paper by training a SpaCKLE model or loading an existing model from a checkpoint to process an AnnData object. This function is essential for reproducing the results of the SpaCKLE method on a given dataset.\n",
    "\n",
    "##### <u>Parameters:</u>\n",
    "\n",
    "* **adata (ad.AnnData):** The AnnData object containing the dataset to be processed. The object must include data splits in adata.obs['split'], with values 'train', 'val', and optionally 'test'.\n",
    "* **dataset (str):** The name of the dataset being used. This name is utilized to organize the results and save paths.\n",
    "* **from_layer (str):** The specific layer in the AnnData object from which the data will be extracted for processing.\n",
    "* **device (str):** The device to run the model on (e.g., 'cpu' or 'cuda').\n",
    "* **lr (float):** The learning rate for training the SpaCKLE model. The default value is 1e-3.\n",
    "* **train (bool):** Indicates whether to train a new model or use an existing one. Default is True.\n",
    "* **load_ckpt_path (str):** The file path to a checkpoint of a previously trained model. If provided, the model will be loaded from this checkpoint, bypassing the training phase. This path should end with the .ckpt file and be located in a directory containing the corresponding script_params.json file. The default is an empty string.\n",
    "* **optimizer (str):** The optimizer to use for training. Default is 'Adam'.\n",
    "* **max_steps (int):** The maximum number of training steps. Default is 1000.\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "The function returns an updated AnnData object that has been processed using the SpaCKLE model. Additionally, during the execution, the function prints performance metrics to the console, either during training or when loading and testing a pre-trained model. The function also saves the model's checkpoints and related parameters in a directory specified by the dataset name and date-time\n",
    "\n",
    "This function is particularly useful for researchers looking to replicate the results of the SpaCKLE model on their own datasets, allowing for both model training and testing with existing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spared.denoising import spackle_cleaner_experiment\n",
    "\n",
    "repro = spackle_cleaner_experiment(adata=adata, dataset=data.dataset, from_layer=\"c_d_log1p\", device=device, lr = 1e-3, train = True, load_ckpt_path = \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Mejia, G., Cárdenas, P., Ruiz, D., Castillo, A., Arbeláez, P.: Sepal: Spatial gene expression prediction from local graphs. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops. pp. 2294–2303 (October 2023)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "H2ST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
