{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpaRED Library Quick Start DEMO\n",
    "\n",
    "This demonstration is a step by step on how to use the SpaRED library to train a gene expression prediction model with pre-trained weights. In this tutorial we will illustrate how to:\n",
    "\n",
    "* Load a SpaRED dataset and save it in an AnnData object.\n",
    "* Prepare the data for training a pretrained model for gene expression prediction.\n",
    "* Initialize a pretrained model.\n",
    "* Train the model using pytorch lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/SSD4/dvegaa/SpaRED/spared\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "\n",
    "currentdir = os.getcwd()\n",
    "parentdir = str(Path(currentdir).parent)\n",
    "sys.path.append(parentdir)\n",
    "print(parentdir)\n",
    "\n",
    "import spared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets\n",
    "\n",
    "The `datasets` file has a function to get any desired dataset and return the adata as well as the parameter dictionary. This function returns a filtered and processed adata. This function has a parameter called *visualize* that allows for all visualizations if set to True. The fuction also saves the raw_adata (not processed) in case it is required. \n",
    "\n",
    "We will begin by loading a dataset and setting the *visualize* parameter as False since no images are required for the functions analized in this DEMO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvegaa/anaconda3/envs/H2ST/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vicari_mouse_brain dataset with the following data split:\n",
      "train data: ['V11L12-038_A1', 'V11L12-038_B1', 'V11L12-038_C1', 'V11L12-038_D1', 'V11L12-109_A1', 'V11L12-109_B1', 'V11L12-109_C1', 'V11L12-109_D1']\n",
      "val data: ['V11T16-085_A1', 'V11T16-085_B1', 'V11T16-085_C1', 'V11T16-085_D1']\n",
      "test data: ['V11T17-101_A1', 'V11T17-101_B1']\n",
      "Parameters already saved in /media/SSD4/dvegaa/SpaRED/spared/spared/processed_data/vicari_data/vicari_mouse_brain/2024-08-11-18-40-39/parameters.json\n",
      "Loading main adata file from disk (/media/SSD4/dvegaa/SpaRED/spared/tutorials/processed_data/vicari_data/vicari_mouse_brain/2024-08-11-18-40-39/adata.h5ad)...\n",
      "The loaded adata object looks like this:\n",
      "AnnData object with n_obs × n_vars = 43804 × 128\n",
      "    obs: 'in_tissue', 'array_row', 'array_col', 'patient', 'slide_id', 'split', 'unique_id', 'n_genes_by_counts', 'total_counts'\n",
      "    var: 'gene_ids', 'feature_types', 'genome', 'gene_symbol', 'exp_frac', 'glob_exp_frac', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'gene_length', 'd_log1p_moran', 'log1p_avg_exp', 'd_log1p_avg_exp', 'c_log1p_avg_exp', 'c_d_log1p_avg_exp'\n",
      "    uns: 'spatial', 'spatial_neighbors'\n",
      "    obsm: 'patches_scale_1.0', 'spatial'\n",
      "    layers: 'c_d_deltas', 'c_d_log1p', 'c_deltas', 'c_log1p', 'c_t_deltas', 'c_t_log1p', 'counts', 'd_deltas', 'd_log1p', 'deltas', 'log1p', 'mask', 'tpm'\n",
      "    obsp: 'spatial_connectivities', 'spatial_distances'\n"
     ]
    }
   ],
   "source": [
    "from spared.datasets import get_dataset\n",
    "\n",
    "#get dataset\n",
    "data = get_dataset(\"vicari_mouse_brain\", visualize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "\n",
    "To train a pretrained model for gene expression prediction, we must first prepare the data. This involves using Dataloaders, a component commonly used in machine learning frameworks like PyTorch to handle the loading of data in an efficient and flexible manner. The function `get_pretrain_dataloaders` receives the following parameters as input:\n",
    "\n",
    "* **adata (ad.AnnData):** AnnData object to process.\n",
    "* **layer (str):** The layer to use for pre-training. Default is set to `c_t_log1p`.\n",
    "* **batch_size (int):** The batch size of the loaders. Default is set to 128.\n",
    "* **shuffle (bool):** Whether to shuffle the data in the loaders. Default is set to True.\n",
    "* **cuda (bool):** Whether to use CUDA in the loaders. Default is set to False.\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "This function returns train, validation, and test dataloaders as a tuple to be used for training a pretrained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of imputed observations with transformer model: 27.503%\n"
     ]
    }
   ],
   "source": [
    "from spared.dataloaders import get_pretrain_dataloaders\n",
    "\n",
    "# Declare train and test loaders\n",
    "train_dataloader, val_dataloader, test_dataloader = get_pretrain_dataloaders(\n",
    "    adata=data.adata,\n",
    "    layer = 'c_t_log1p',\n",
    "    batch_size = 265,\n",
    "    shuffle = True,\n",
    "    use_cuda = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model\n",
    "\n",
    "The SpaRED library provides a function to  initilize a model with pretrained weights for gene expression prediction. The function `ImageBackbone` class receives the following inputs:\n",
    "\n",
    "* **args (argparse):** Argument parser with specific variables required to initialize the model.\n",
    "* **latem_dim (int):** Latent dimensions used as output feature dimensions in the last layer of the defined model.\n",
    "\n",
    "##### <u>Returns:</u>\n",
    "\n",
    "The function returns the initialized model. The backbone used for pretrained weights is defined in the argparse parameters. In this demo, we will use ShuffleNetV2. You can check the available backbones in the documentation of the SpaRED library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageBackbone(\n",
       "  (test_transforms): Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "  (criterion): MSELoss()\n",
       "  (encoder): ShuffleNetV2(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (stage2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (branch1): Sequential(\n",
       "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
       "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (4): ReLU(inplace=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
       "          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (branch1): Sequential(\n",
       "          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (4): ReLU(inplace=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
       "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (branch1): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (4): ReLU(inplace=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv5): Sequential(\n",
       "      (0): Conv2d(192, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spared.models import ImageBackbone\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "# Define argparse variables\n",
    "test_args = argparse.Namespace()\n",
    "arg_dict = vars(test_args)\n",
    "input_dict = {\n",
    "    'img_backbone': 'ShuffleNetV2',\n",
    "    'img_use_pretrained': True,\n",
    "    'average_test': False,\n",
    "    'optim_metric': 'MSE',\n",
    "    'robust_loss': False,\n",
    "    'optimizer': 'Adam',\n",
    "    'lr': 0.0001,\n",
    "    'momentum': 0.9,\n",
    "}\n",
    "\n",
    "for key,value in input_dict.items():\n",
    "    arg_dict[key]= value\n",
    "\n",
    "\n",
    "# Declare device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ImageBackbone(args=test_args,  latent_dim=data.adata.n_vars).to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "Now we will use PyTorch Lightning to train the model. First, we must define a `ModelCheckpoint` callback to monitor the validation mean squared error (val_MSE) and save only the best model based on this metric. Then, we initialize a `Trainer` and define various parameters. In this case our model will run for a maximum of 1000 training steps, perform validation every 10 steps, log progress every 10 steps, and use one GPU for training. Additionally, the trainer displays a progress bar and a model summary during training. This setup ensures efficient model training and validation, with automatic saving of the best model based on the specified validation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define checkpoint callback to save best model in validation\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=f'val_MSE', # Choose your validation metric\n",
    "    save_top_k=1, # Save only the best model\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Define the trainier and fit the model\n",
    "trainer = Trainer(\n",
    "    max_steps=30,\n",
    "    val_check_interval=10,\n",
    "    log_every_n_steps=10,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    check_val_every_n_epoch=None,\n",
    "    devices=[6],\n",
    "    enable_progress_bar=True,\n",
    "    enable_model_summary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we must begin the training process using PyTorch Lightning's `Trainer` with the `fit` method. The `fit` method is called with the specified model, training data loader (train_dataloader), and validation data loader (val_dataloader). This setup allows the Trainer to manage the training loop, including feeding the model with training data, performing validation at specified intervals, and utilizing the previously defined configurations and callbacks for efficient training and model checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name            | Type         | Params\n",
      "-------------------------------------------------\n",
      "0 | test_transforms | Normalize    | 0     \n",
      "1 | criterion       | MSELoss      | 0     \n",
      "2 | encoder         | ShuffleNetV2 | 472 K \n",
      "-------------------------------------------------\n",
      "472 K     Trainable params\n",
      "0         Non-trainable params\n",
      "472 K     Total params\n",
      "1.892     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  33%|███▎      | 30/90 [02:39<05:18,  0.19it/s, v_num=5]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  33%|███▎      | 30/90 [02:39<05:18,  0.19it/s, v_num=5]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models performance\n",
    "\n",
    "After training, the path to the best model is obtained from the `checkpoint_callback`. We can use the best model to evaluate performance on the test set (if available). We load the model from the `checkpoint_callback` path and use the `trainer.test` method to evaluate the model's performance on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/SSD4/dvegaa/SpaRED/spared/tutorials/lightning_logs/version_5/checkpoints/epoch=0-step=30.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 26/26 [00:19<00:00,  1.30it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       test_Global          -240.42971801757812\n",
      "        test_MAE             9.327844619750977\n",
      "        test_MSE             90.31873321533203\n",
      "      test_PCC-Gene        -0.07831642031669617\n",
      "     test_PCC-Patch        0.020641593262553215\n",
      "      test_R2-Gene          -110.23809814453125\n",
      "      test_R2-Patch         -30.487369537353516\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# Load the best model after training\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "print(best_model_path)\n",
    "model = ImageBackbone.load_from_checkpoint(best_model_path)\n",
    "\n",
    "# Test model if there is a test dataloader\n",
    "if not (test_dataloader is None):\n",
    "    trainer.test(model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/SSD4/dvegaa/SpaRED/spared/tutorials/lightning_logs/version_5/checkpoints/epoch=0-step=30.ckpt\n"
     ]
    }
   ],
   "source": [
    "print(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_predictions(dataloader, model, device=\"cuda\")->None:\n",
    "    # Set model to eval mode\n",
    "    model=model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    glob_expression_pred = None\n",
    "    # Get complete predictions\n",
    "    with torch.no_grad():\n",
    "        for b in tqdm(range(0,len(test_dataloader.dataset))):\n",
    "            batch = dataloader.dataset[b]\n",
    "            expression_pred, expression_gt, mask = model.test_step(batch)\n",
    "            expression_pred = expression_pred.cpu()\n",
    "\n",
    "            # Concat batch to get global predictions and IDs\n",
    "            glob_expression_pred = expression_pred if glob_expression_pred is None else torch.cat((glob_expression_pred, expression_pred))\n",
    "\n",
    "    return glob_expression_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6730 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6730/6730 [49:06<00:00,  2.28it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Put complete predictions in a single dataframe\n",
    "glob_expression_pred = get_predictions(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6730, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob_expression_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "        \n",
    "# Put complete predictions in a single dataframe\n",
    "adata_test = data.adata[data.adata.obs[\"split\"] == \"test\"]\n",
    "pred_matrix = glob_expression_pred\n",
    "glob_ids = adata_test.obs['unique_id'].tolist()\n",
    "pred_df = pd.DataFrame(pred_matrix, index=glob_ids, columns=adata_test.var_names)\n",
    "pred_df = pred_df.reindex(adata_test.obs.index)\n",
    "\n",
    "# Add layer to adata\n",
    "layer = \"c_t_log1p\"\n",
    "adata_test.layers[f'predictions,{layer}'] = pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 6730 × 128\n",
       "    obs: 'in_tissue', 'array_row', 'array_col', 'patient', 'slide_id', 'split', 'unique_id', 'n_genes_by_counts', 'total_counts'\n",
       "    var: 'gene_ids', 'feature_types', 'genome', 'gene_symbol', 'exp_frac', 'glob_exp_frac', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'gene_length', 'd_log1p_moran', 'log1p_avg_exp', 'd_log1p_avg_exp', 'c_log1p_avg_exp', 'c_d_log1p_avg_exp'\n",
       "    uns: 'spatial', 'spatial_neighbors'\n",
       "    obsm: 'patches_scale_1.0', 'spatial'\n",
       "    layers: 'c_d_deltas', 'c_d_log1p', 'c_deltas', 'c_log1p', 'c_t_deltas', 'c_t_log1p', 'counts', 'd_deltas', 'd_log1p', 'deltas', 'log1p', 'mask', 'tpm', 'noisy', 'predictions,c_t_log1p'\n",
       "    obsp: 'spatial_connectivities', 'spatial_distances'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./prediction_images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspared\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m log_pred_image\n\u001b[0;32m----> 2\u001b[0m \u001b[43mlog_pred_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_genes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./prediction_images\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/SSD4/dvegaa/SpaRED/spared/spared/plotting/plotting.py:1113\u001b[0m, in \u001b[0;36mlog_pred_image\u001b[0;34m(adata, n_genes, slides, save_path)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gene \u001b[38;5;129;01min\u001b[39;00m selected_genes:\n\u001b[0;32m-> 1113\u001b[0m     \u001b[43mlog_one_gene\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgene\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1115\u001b[0m log_pred_correlations(adata, pred_layer, save_path)\n\u001b[1;32m   1116\u001b[0m log_mean_variance(adata, pred_layer, save_path)\n",
      "File \u001b[0;32m/media/SSD4/dvegaa/SpaRED/spared/spared/plotting/plotting.py:934\u001b[0m, in \u001b[0;36mlog_pred_image.<locals>.log_one_gene\u001b[0;34m(adata, gene, slides, gt_layer, pred_layer, save_path)\u001b[0m\n\u001b[1;32m    931\u001b[0m row \u001b[38;5;241m=\u001b[39m order_dict[p]\n\u001b[1;32m    933\u001b[0m curr_img \u001b[38;5;241m=\u001b[39m slides_adatas_dict[p]\u001b[38;5;241m.\u001b[39muns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspatial\u001b[39m\u001b[38;5;124m'\u001b[39m][slides[p]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowres\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 934\u001b[0m \u001b[43max\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mimshow(curr_img)\n\u001b[1;32m    935\u001b[0m ax[row,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mslides[p]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPCC-Gene=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(adata\u001b[38;5;241m.\u001b[39mvar\u001b[38;5;241m.\u001b[39mloc[gene,\u001b[38;5;250m \u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpcc_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlarge\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    936\u001b[0m ax[row,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_xticks([])\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1300x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spared.plotting import log_pred_image\n",
    "log_pred_image(adata_test, n_genes=2, slides={}, save_path='./prediction_images')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
